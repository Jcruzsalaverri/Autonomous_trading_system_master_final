{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"3.2-Time_tick_bars_Dagostino_Pearson.ipynb","provenance":[],"collapsed_sections":["j7aX6P1h8AsI","2hyBI7Jf64Ih","WuImnwPt7Av1","PHwEnJeH7pbB","UaxSjwSd8Wq9","a8qFvVJD8pwB","sVNH2WVw8_Ip","40ZKGAhM9fgB","rZqwp9B6GYH8","LyQW2kccICVx","xKWFANTGGxIZ"],"machine_shape":"hm","authorship_tag":"ABX9TyMxh70iEhpz5EX8eDATebg2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSML2C6Q1q-7","executionInfo":{"status":"ok","timestamp":1639422232210,"user_tz":-60,"elapsed":14683,"user":{"displayName":"Snse Crew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAOHw-xEwwRXhyAHeEkhxaQ-xFE9qjVFAAxuCj=s64","userId":"18253393771672979153"}},"outputId":"ae45a7e8-bcd6-4023-d293-3bab30e4cb7b"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOPNBnk52NKw","executionInfo":{"status":"ok","timestamp":1632216020193,"user_tz":-120,"elapsed":27,"user":{"displayName":"Snse Crew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAOHw-xEwwRXhyAHeEkhxaQ-xFE9qjVFAAxuCj=s64","userId":"18253393771672979153"}},"outputId":"487f48ff-cc8f-41b5-e369-db0dcec5e9fe"},"source":["cd gdrive/My Drive/TFM/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/TFM\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcUqYefw2Pdw","executionInfo":{"status":"ok","timestamp":1632216025866,"user_tz":-120,"elapsed":5679,"user":{"displayName":"Snse Crew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAOHw-xEwwRXhyAHeEkhxaQ-xFE9qjVFAAxuCj=s64","userId":"18253393771672979153"}},"outputId":"39fb6f30-2659-4795-f3ff-a7b7534e8c7d"},"source":["import os\n","import glob\n","\n","\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import matplotlib.pyplot as plt\n","import cufflinks as cf\n","\n","import seaborn as sns\n","\n","!pip install --upgrade mplfinance\n","import mplfinance as mpf\n","\n","from scipy import stats"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mplfinance\n","  Downloading mplfinance-0.12.7a17-py3-none-any.whl (62 kB)\n","\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 51 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 62 kB 826 kB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.1.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.3.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.19.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->mplfinance) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2018.9)\n","Installing collected packages: mplfinance\n","Successfully installed mplfinance-0.12.7a17\n"]}]},{"cell_type":"markdown","source":["#aux methods"],"metadata":{"id":"j7aX6P1h8AsI"}},{"cell_type":"code","source":["#Serial correlation aka auto correlation\n","\n","def returns(candles_close_prices):\n","    #return pd.Series(np.diff(candles_close_prices))\n","    return np.log(candles_close_prices).diff().dropna()"],"metadata":{"id":"E5Nk1o-U8BoT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Dagostion Pearson test for several assets. Tick and Time bars for several timeframes"],"metadata":{"id":"AEQ1u79K6qx6"}},{"cell_type":"code","source":["time_frames = ['5min','15m','30m','1h','4h','12h']\n","tick_frames = ['50', '100', '200', '500', '1000']\n","volume_frames = []\n","column_names = ['Time-5m','Time-15m','Time-30m','Time-1h','Time-4h','Time-12h','Tick-50', 'Tick-100', 'Tick-200', 'Tick-500', 'Tick-1000' ]\n","row_names = ['ADAUSDT','BNBUSDT','EOSUSDT','DOTUSDT','ETHUSD','LINKUSDT','LTCUSD','XTZUSDT','XBTUSD','XRPUSD']\n","\n","def bar(xs, y): return np.int64(xs / y) * y\n","\n","correlations = pd.DataFrame(columns = column_names,index = row_names )"],"metadata":{"id":"nngYDvaL8IB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw trade data from https://public.bitmex.com/?prefix=data/trade/ \n","data = pd.DataFrame()\n","for i,file in enumerate(glob.glob(\"data/test/Data_0/*.csv\")):\n","  if i == 0:\n","    data = data.append(pd.read_csv(file))\n","    print('Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_0/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_0/*.csv\"))-i, \"files left\", end='')\n","  else:\n","    data = data.append(pd.read_csv(file))\n","    print('\\r Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_0/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_0/*.csv\"))-i, \"files left\",end='', flush=True)\n"],"metadata":{"id":"wZ_lmgG7Yc5l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw trade data from https://public.bitmex.com/?prefix=data/trade/ \n","data = pd.DataFrame()\n","for i,file in enumerate(glob.glob(\"data/test/Data_1/*.csv\")):\n","  if i == 0:\n","    data = data.append(pd.read_csv(file))\n","    print('Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_1/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_1/*.csv\"))-i, \"files left\", end='')\n","  else:\n","    data = data.append(pd.read_csv(file))\n","    print('\\r Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_1/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_1/*.csv\"))-i, \"files left\",end='', flush=True)\n","\n"],"metadata":{"id":"jY8rgNFvYdn8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw trade data from https://public.bitmex.com/?prefix=data/trade/ \n","data = pd.DataFrame()\n","for i,file in enumerate(glob.glob(\"data/test/Data_2/*.csv\")):\n","  if i == 0:\n","    data = data.append(pd.read_csv(file))\n","    print('Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_2/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_2/*.csv\"))-i, \"files left\", end='')\n","  else:\n","    data = data.append(pd.read_csv(file))\n","    print('\\r Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_2/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_2/*.csv\"))-i, \"files left\",end='', flush=True)\n"],"metadata":{"id":"sHL09UgvYfsT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw trade data from https://public.bitmex.com/?prefix=data/trade/ \n","data = pd.DataFrame()\n","for i,file in enumerate(glob.glob(\"data/test/Data_3/*.csv\")):\n","  if i == 0:\n","    data = data.append(pd.read_csv(file))\n","    print('Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_3/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_3/*.csv\"))-i, \"files left\", end='')\n","  else:\n","    data = data.append(pd.read_csv(file))\n","    print('\\r Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_3/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_3/*.csv\"))-i, \"files left\",end='', flush=True)\n"],"metadata":{"id":"5us8cI6aYiVp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##ADA"],"metadata":{"id":"2hyBI7Jf64Ih"}},{"cell_type":"code","metadata":{"id":"OftEcUb-LAfM"},"source":["data1 = data[data.symbol == 'ADAUSDTH21']\n","\n","# timestamp parsing\n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":414},"id":"eX8vY7uTvX5K","executionInfo":{"status":"ok","timestamp":1632216766738,"user_tz":-120,"elapsed":398,"user":{"displayName":"Snse Crew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAOHw-xEwwRXhyAHeEkhxaQ-xFE9qjVFAAxuCj=s64","userId":"18253393771672979153"}},"outputId":"1997c47a-4a67-4f56-8b2e-30d4428ab2d4"},"source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Time-1h'] = stats.normaltest(Time_bars_1h['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","correlations\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ADAUSDT','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","correlations\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time-5m</th>\n","      <th>Time-15m</th>\n","      <th>Time-30m</th>\n","      <th>Time-1h</th>\n","      <th>Time-4h</th>\n","      <th>Time-12h</th>\n","      <th>Tick-50</th>\n","      <th>Tick-100</th>\n","      <th>Tick-200</th>\n","      <th>Tick-500</th>\n","      <th>Tick-1000</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ADAUSDT</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.10885e-223</td>\n","      <td>2.72638e-121</td>\n","      <td>6.2501e-33</td>\n","      <td>1.4606e-12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.40638e-54</td>\n","    </tr>\n","    <tr>\n","      <th>BNBUSDT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>DOGEUSDT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>DOTUSDT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ETHUSD</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>LINKUSDT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>SOLUSDT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>XLMUSDT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>TRXUSDT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>UNIUSDT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>XBTUSD</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>XRPUSD</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Time-5m Time-15m      Time-30m  ... Tick-200 Tick-500    Tick-1000\n","ADAUSDT        0        0  1.10885e-223  ...        0        0  7.40638e-54\n","BNBUSDT      NaN      NaN           NaN  ...      NaN      NaN          NaN\n","DOGEUSDT     NaN      NaN           NaN  ...      NaN      NaN          NaN\n","DOTUSDT      NaN      NaN           NaN  ...      NaN      NaN          NaN\n","ETHUSD       NaN      NaN           NaN  ...      NaN      NaN          NaN\n","LINKUSDT     NaN      NaN           NaN  ...      NaN      NaN          NaN\n","SOLUSDT      NaN      NaN           NaN  ...      NaN      NaN          NaN\n","XLMUSDT      NaN      NaN           NaN  ...      NaN      NaN          NaN\n","TRXUSDT      NaN      NaN           NaN  ...      NaN      NaN          NaN\n","UNIUSDT      NaN      NaN           NaN  ...      NaN      NaN          NaN\n","XBTUSD       NaN      NaN           NaN  ...      NaN      NaN          NaN\n","XRPUSD       NaN      NaN           NaN  ...      NaN      NaN          NaN\n","\n","[12 rows x 11 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["##BNB"],"metadata":{"id":"WuImnwPt7Av1"}},{"cell_type":"code","metadata":{"id":"c46FdckMyTy5","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"error","timestamp":1632216767104,"user_tz":-120,"elapsed":381,"user":{"displayName":"Snse Crew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAOHw-xEwwRXhyAHeEkhxaQ-xFE9qjVFAAxuCj=s64","userId":"18253393771672979153"}},"outputId":"30d6a5c1-b396-45cb-96b9-cd14f0f27f27"},"source":["data1 = data[data.symbol == 'BNBUSDTH21']\n","\n","# timestamp parsing\n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-3e9be9e53c42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'BNBUSDT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# timestamp parsing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%Y-%m-%dD%H:%M:%S.%f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]},{"cell_type":"code","metadata":{"id":"1jbiK_5ORBCM"},"source":["\n","stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"akqYztXoxnf7"},"source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Time-15m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Time-30m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Time-1h'] = stats.normaltest(Time_bars_1h['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","correlations\n","\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['BNBUSDT','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","correlations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##EOS"],"metadata":{"id":"PHwEnJeH7pbB"}},{"cell_type":"code","source":["data1 = data[data.symbol == 'EOSUSDTH21']\n","\n","# timestamp parsing\n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"bTzGa6ai7u0F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Time-1h'] = stats.normaltest(Time_bars_1h['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","correlations\n","\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['EOSUSDT','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","correlations"],"metadata":{"id":"l_i6H6U48On4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##DOT"],"metadata":{"id":"UaxSjwSd8Wq9"}},{"cell_type":"code","source":["data1 = data[data.symbol == 'DOTUSDTH21']\n","\n","# timestamp parsing\n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"XpHuQ3Tn8d4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Ev_FBG20j1n"},"source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Time-1h'] = stats.normaltest(Time_bars_1h['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","correlations\n","\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['DOTUSDT','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","correlations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##ETH"],"metadata":{"id":"a8qFvVJD8pwB"}},{"cell_type":"code","source":["data1 = data[data.symbol == 'ETHUSD']\n","\n","# timestamp parsing\n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"_vgn8tS28zft"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dFq1UsJ20uv2"},"source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Time-1h'] = stats.normaltest(Time_bars_1h['close'])[1]\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","correlations\n","\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['ETHUSD','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","correlations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##LINK"],"metadata":{"id":"sVNH2WVw8_Ip"}},{"cell_type":"code","metadata":{"id":"nyqPWO6lzo8A"},"source":["data1 = data[data.symbol == 'LINKUSDT'] \n","# timestamp parsing\n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70Im70ks07RU"},"source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Time-1h'] = stats.normaltest(Time_bars_1h['close'])[1]\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Time-12h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LINKUSDT','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","correlations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##LTC"],"metadata":{"id":"40ZKGAhM9fgB"}},{"cell_type":"code","source":["data1 = data[data.symbol == 'LTCUSD']\n","\n","# timestamp parsing \n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"DdN3xR4VFnSb"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqiS0V1P1K6L"},"source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Time-1h'] = stats.normaltest(Time_bars_1h['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['LTCUSD','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","correlations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##XTZ"],"metadata":{"id":"rZqwp9B6GYH8"}},{"cell_type":"code","source":["data1 = data[data.symbol == 'XTZUSDTH21']\n","# timestamp parsing \n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"tzLxwaMHGcyc"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8JtsWZ5N2Iq3"},"source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Time-1h'] = stats.normaltest(Time_bars_1h['close'],nan_policy='omit')[1]\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","correlations\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XTZUSDT','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","correlations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##YFI"],"metadata":{"id":"LyQW2kccICVx"}},{"cell_type":"code","source":["data1 = data[data.symbol == 'YFIUSDTH21']\n","# timestamp parsing \n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"FVbWHpD0IH9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["correlations.append(pd.Series(name='YFIUSDT'))"],"metadata":{"id":"UeLRj42JJO-f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Time-1h'] = stats.normaltest(Time_bars_1h['close'],nan_policy='omit')[1]\n","\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","correlations\n","\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['YFIUSDT','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","\n","correlations"],"metadata":{"id":"K48OuY7XIS2Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##XBT"],"metadata":{"id":"qrn8MoAzIe6N"}},{"cell_type":"code","source":["data1 = data[data.symbol == 'XBTUSD']\n","# timestamp parsing \n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"iXVz7s8_Ihui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Time-1h'] = stats.normaltest(Time_bars_1h['close'],nan_policy='omit')[1]\n","\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","correlations\n","\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XBTUSD','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","\n","correlations"],"metadata":{"id":"8kA5DGKwIwl8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##XRP"],"metadata":{"id":"xKWFANTGGxIZ"}},{"cell_type":"code","metadata":{"id":"9QkDqt6jIeFO"},"source":["data1 = data[data.symbol == 'XRPUSD']\n","# timestamp parsing \n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mg2DwBHp2X80"},"source":["Time_bars_5m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"5min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_5m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Time-5m'] = stats.normaltest(Time_bars_5m['close'],nan_policy='omit')[1]\n","\n","\n","\n","Time_bars_15m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"15min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_15m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Time-15m'] = stats.normaltest(Time_bars_15m['close'],nan_policy='omit')[1]\n","\n","\n","\n","\n","Time_bars_30m = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"30min\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_30m.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Time-30m'] = stats.normaltest(Time_bars_30m['close'],nan_policy='omit')[1]\n","\n","\n","\n","\n","Time_bars_1h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_1h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Time-1h'] = stats.normaltest(Time_bars_1h['close'],nan_policy='omit')[1]\n","\n","\n","\n","Time_bars_4h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"4h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_4h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Time-4h'] = stats.normaltest(Time_bars_4h['close'])[1]\n","\n","\n","\n","Time_bars_12h = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"12h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","Time_bars_12h.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Time-12h'] = stats.normaltest(Time_bars_12h['close'])[1]\n","correlations\n","\n","\n","\n","Tick_50 = data1.groupby(bar(np.arange(len(data1)), 50 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_50.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Tick-50'] = stats.normaltest(Tick_50['close'])[1]\n","\n","\n","\n","Tick_100 = data1.groupby(bar(np.arange(len(data1)), 100 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_100.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Tick-100'] = stats.normaltest(Tick_100['close'])[1]\n","\n","\n","\n","Tick_200 = data1.groupby(bar(np.arange(len(data1)), 200 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_200.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Tick-200'] = stats.normaltest(Tick_200['close'])[1]\n","\n","\n","\n","Tick_500 = data1.groupby(bar(np.arange(len(data1)), 500 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_500.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Tick-500'] = stats.normaltest(Tick_500['close'])[1]\n","\n","\n","Tick_1000 = data1.groupby(bar(np.arange(len(data1)), 1000 )).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","Tick_1000.columns = ['open','high','low','close','size','timestamp']\n","correlations.at['XRPUSD','Tick-1000'] = stats.normaltest(Tick_1000['close'])[1]\n","\n","\n","\n","correlations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Heatmap"],"metadata":{"id":"4P22bgnkHqfE"}},{"cell_type":"code","metadata":{"id":"9puxLKea79Lm"},"source":["cormat = np.array(correlations,dtype='float64')\n","\n","fig, ax = plt.subplots(figsize=(15,15))         # Sample figsize in inches\n","corrmat =  sns.heatmap(cormat, annot = True, linewidths=.5, ax=ax, xticklabels=column_names,\n","                       yticklabels=row_names,  cbar_kws={'label': 'P-value'})\n","\n","ax.xaxis.set_ticks_position('top')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R6m_4bfoy3fh"},"source":["from google.colab import files\n","fig = corrmat.get_figure()\n","fig.savefig('Dagostino_Time_Volume.png')\n"],"execution_count":null,"outputs":[]}]}