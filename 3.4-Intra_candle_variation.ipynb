{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.4-Intra_candle_variation.ipynb","provenance":[],"collapsed_sections":["BFOXuYCWzrZF"],"authorship_tag":"ABX9TyPWYuBqoW/cK9zkvJ9bVvzc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"zITnWuzlcsoi"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hB-8N1OVc4NT"},"source":["cd gdrive/My Drive/TFM/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1te6D8Wc557"},"source":["import os\n","import glob\n","\n","\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","\n","#import plotly.express as px\n","\n","import matplotlib.pyplot as plt\n","import cufflinks as cf\n","\n","!pip install plotly==5.3.1\n","!pip install -U kaleido\n","\n","import plotly.io as pio\n","from plotly.subplots import make_subplots\n","import plotly.graph_objects as go\n","\n","\n","import sys\n","\n","import seaborn as sns\n","\n","from scipy import stats"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Test data loading "],"metadata":{"id":"qAs7hDtgzdfq"}},{"cell_type":"code","metadata":{"id":"bgi690X5dKZ_"},"source":["# raw trade data from https://public.bitmex.com/?prefix=data/trade/ \n","data = pd.DataFrame()\n","for i,file in enumerate(glob.glob(\"data/test/Data_0/*.csv\")):\n","  if i == 0:\n","    data = data.append(pd.read_csv(file))\n","    print('Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_0/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_0/*.csv\"))-i, \"files left\", end='')\n","  else:\n","    data = data.append(pd.read_csv(file))\n","    print('\\r Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_0/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_0/*.csv\"))-i, \"files left\",end='', flush=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VSb9d4cegSJ"},"source":["data1 = data[data.symbol == 'ETHUSD']\n","del(data)\n","# timestamp parsing\n","data1['timestamp'] = data1.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw trade data from https://public.bitmex.com/?prefix=data/trade/ \n","data = pd.DataFrame()\n","for i,file in enumerate(glob.glob(\"data/test/Data_1/*.csv\")):\n","  if i == 0:\n","    data = data.append(pd.read_csv(file))\n","    print('Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_1/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_1/*.csv\"))-i, \"files left\", end='')\n","  else:\n","    data = data.append(pd.read_csv(file))\n","    print('\\r Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_1/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_1/*.csv\"))-i, \"files left\",end='', flush=True)\n","\n"],"metadata":{"id":"fIEexUjBoHhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data2 = data[data.symbol == 'ETHUSD']\n","del(data)\n","# timestamp parsing\n","data2['timestamp'] = data2.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"qbIfBH5hoJE6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw trade data from https://public.bitmex.com/?prefix=data/trade/ \n","data = pd.DataFrame()\n","for i,file in enumerate(glob.glob(\"data/test/Data_2/*.csv\")):\n","  if i == 0:\n","    data = data.append(pd.read_csv(file))\n","    print('Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_2/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_2/*.csv\"))-i, \"files left\", end='')\n","  else:\n","    data = data.append(pd.read_csv(file))\n","    print('\\r Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_2/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_2/*.csv\"))-i, \"files left\",end='', flush=True)\n"],"metadata":{"id":"elFfFdyhoKcM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data3 = data[data.symbol == 'ETHUSD']\n","del(data)\n","# timestamp parsing\n","data3['timestamp'] = data3.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"bWANB2fvoM2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw trade data from https://public.bitmex.com/?prefix=data/trade/ \n","data = pd.DataFrame()\n","for i,file in enumerate(glob.glob(\"data/test/Data_3/*.csv\")):\n","  if i == 0:\n","    data = data.append(pd.read_csv(file))\n","    print('Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_3/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_3/*.csv\"))-i, \"files left\", end='')\n","  else:\n","    data = data.append(pd.read_csv(file))\n","    print('\\r Percentge of files already Loaded:',round((i/len(glob.glob(\"data/test/Data_3/*.csv\")))*100,1), '%. There are', len(glob.glob(\"data/test/Data_3/*.csv\"))-i, \"files left\",end='', flush=True)\n"],"metadata":{"id":"jSncQgMYqgwz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data4 = data[data.symbol == 'ETHUSD']\n","del(data)\n","# timestamp parsing\n","data4['timestamp'] = data4.timestamp.map(lambda t: datetime.strptime(t[:-3], \"%Y-%m-%dD%H:%M:%S.%f\"))"],"metadata":{"id":"-1BRTY2BqhpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1.append(data2)\n","del(data2)\n","data1.append(data3)\n","del(data3)\n","data1.append(data4)\n","del(data4)\n"],"metadata":{"id":"YexsNyiRoRQs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Time sampling \n","** avg_dly_tick must be modified for each dataset"],"metadata":{"id":"BFOXuYCWzrZF"}},{"cell_type":"code","metadata":{"id":"iBNSRcQJg8IG"},"source":["Time_bars_1d = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1d\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first', 'foreignNotional':'sum' })\n","Time_bars_1d.columns = ['open','high','low','close','size','timestamp','foreignNotional']\n","\n","avg_dly_dollar = np.mean(Time_bars_1d['foreignNotional'])\n","\n","avg_1h_dollar = np.round(avg_dly_dollar/24,decimals=-2)\n","\n","avg_dly_volume = np.mean(Time_bars_1d['size'])\n","\n","avg_1h_volume = np.round(avg_dly_volume/24,decimals=-2)\n","\n","\n","\n","\n","delta = data1['timestamp'][-1]-data1['timestamp'][0]\n","avg_dly_tick = delta.days\n","\n","\n","\n","\n","\n","avg_dly_tick = len(data1)/88\n","\n","avg_1h_tick = np.round(avg_dly_tick/24,decimals=-2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"89v_ktHxdL2g"},"source":["\n","#TIME BARS\n","\n","Time_bars = data1.groupby(pd.Grouper(key=\"timestamp\", freq=\"1h\")).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first' })\n","\n","\n","Time_bars.columns = ['open','high','low','close','size','timestamp']\n","\n","\n","Time_bars['variation'] = ((Time_bars['high']-Time_bars['low'])/Time_bars['high'])*100\n","\n","#VOLUME BARS\n","\n","n = avg_1h_volume;\n","\n","def bar(xs, y): return np.int64(xs / y) * y\n","\n","#Volume_bars = data.groupby(bar(np.cumsum(data['size']), n)).agg({'price': 'ohlc', 'size': 'sum'})\n","Volume_bars = data1.groupby(bar(np.cumsum(data1['size']), n)).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","\n","Volume_bars.columns = ['open','high','low','close','size','timestamp']\n","\n","\n","Volume_bars['variation'] = ((Volume_bars['high']-Volume_bars['low'])/Volume_bars['high'])*100\n","\n","\n","#TICK BARS\n","\n","\n","n = avg_1h_tick;\n","\n","def bar(xs, y): return np.int64(xs / y) * y\n","\n","Tick_bars = data1.groupby(bar(np.arange(len(data1)), n)).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","\n","\n","Tick_bars.columns = ['open','high','low','close','size','timestamp']\n","\n","\n","Tick_bars['variation'] = ((Tick_bars['high']-Tick_bars['low'])/Tick_bars['high'])*100\n","\n","\n","#DOLLAR BARS\n","\n","n = avg_1h_dollar\n","\n","\n","Dollar_bars = data1.groupby(bar(np.cumsum(data1['foreignNotional']), n)).agg({'price': 'ohlc', 'size': 'sum', 'timestamp': 'first'})\n","\n","\n","Dollar_bars.columns = ['open','high','low','close','size','timestamp']\n","\n","\n","Dollar_bars['variation'] = ((Dollar_bars['high']-Dollar_bars['low'])/Dollar_bars['high'])*100\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Intra candle variation plot for Time, Tick, Volume and Dollar bars"],"metadata":{"id":"B7gIPmZ10Egm"}},{"cell_type":"code","metadata":{"id":"QtTuAy2gzP15"},"source":["Dollar_bars_dates = pd.DataFrame({'timestamps' : Dollar_bars['timestamp']})\n","Dollar_bars_dates.set_index('timestamps', inplace=True) # set column 'date' to index\n","Dollar_bars_dates['count'] = \"1\"\n","\n","Daily_occurences = Dollar_bars_dates.groupby(Dollar_bars_dates.index.date).count()\n","Daily_occurences['timestamp'] = Daily_occurences.index\n","\n","\n","# Create figure with secondary y-axis\n","fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n","\n","\n","fig.add_trace(go.Bar(x = Daily_occurences['timestamp'], y=Daily_occurences['count'],\n","                name=\"<b>Daily Dollar Bars</b>\"))\n","\n","\n","Tick_bar_dates = pd.DataFrame({'timestamps' : Tick_bars['timestamp']})\n","Tick_bar_dates.set_index('timestamps', inplace=True) # set column 'date' to index\n","Tick_bar_dates['count'] = \"1\"\n","\n","Daily_occurences_tick = Tick_bar_dates.groupby(Tick_bar_dates.index.date).count()\n","Daily_occurences_tick['timestamp'] = Daily_occurences_tick.index\n","\n","\n","\n","fig.add_trace(go.Bar(x=Daily_occurences_tick['timestamp'], y=Daily_occurences_tick['count'],\n","                name=\"<b>Daily Tick Bars</b>\"))\n","\n","Time_bar_dates = pd.DataFrame({'timestamps' : Time_bars['timestamp']})\n","Time_bar_dates.set_index('timestamps', inplace=True) # set column 'date' to index\n","Time_bar_dates['count'] = \"1\"\n","\n","Daily_occurences_time = Time_bar_dates.groupby(Time_bar_dates.index.date).count()\n","Daily_occurences_time['timestamp'] = Daily_occurences_time.index\n","\n","\n","#fig.add_trace(go.Bar(x=Daily_occurences_time['timestamp'], y=Daily_occurences_time['count'],\n","#                name=\"<b>Daily Time Bars</b>\"))\n","fig.add_trace(go.Scatter(x=Daily_occurences_time['timestamp'], y=Daily_occurences_time['count'],\n","                name=\"<b>Daily Time Bars</b>\"))\n","\n","Volume_bar_dates = pd.DataFrame({'timestamps' : Volume_bars['timestamp']})\n","Volume_bar_dates.set_index('timestamps', inplace=True) # set column 'date' to index\n","Volume_bar_dates['count'] = \"1\"\n","\n","Daily_occurences_volume = Volume_bar_dates.groupby(Volume_bar_dates.index.date).count()\n","Daily_occurences_volume['timestamp'] = Daily_occurences_volume.index\n","\n","\n","fig.add_trace(go.Bar(x=Daily_occurences_volume['timestamp'], y=Daily_occurences_volume['count'],\n","                name=\"<b>Daily Volume Bars</b>\"))\n","\n","\n","Asset_price_dates = pd.DataFrame({'timestamps' : Time_bars['timestamp'] , 'price' : Time_bars['close'] })\n","Asset_price_dates.set_index('timestamps', inplace=True) # set column 'date' to index\n","Asset_price_dates['timestamps'] = Asset_price_dates.index\n","\n","fig.add_trace(go.Scatter(\n","    x=Asset_price_dates['timestamps'],\n","    y=np.log(Asset_price_dates['price']),\n","    name=\"ETHUSD closing price\",\n","    mode = 'lines+text',\n","    textfont_family=\"Arial_Black\"),\n","    secondary_y=True,\n","\n",")\n","fig.update_layout(\n","    legend=dict(\n","        x=0.0,\n","        y=0.98,\n","        traceorder=\"normal\",\n","        font=dict(\n","            family=\"sans-serif\",\n","            size=12,\n","            color=\"black\"\n","        ),\n","    )\n",")\n","\n","fig.update_yaxes(title_text=\"<b> Candles per day </b>\", secondary_y=False)\n","fig.update_yaxes(title_text=\"<b> ETHUSD Log price\", secondary_y=True)\n","\n","fig.update_layout(\n","    xaxis_title=\"<b>Days</b>\",\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vuoMfvWd_LYw"},"source":["pio.write_image(fig, 'Sample_rate_comparation.png', width=1720, height=540)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lIh78fbVeTGy"},"source":["counts, bins = np.histogram(Dollar_bars.variation, bins=np.linspace(0,4,50))\n","\n","counts1, bins1 = np.histogram(Volume_bars.variation, bins=np.linspace(0,4,50))\n","\n","counts2, bins2 = np.histogram(Time_bars.variation, bins=np.linspace(0,4,50))\n","\n","counts3, bins3 = np.histogram(Tick_bars.variation, bins=np.linspace(0,4,50))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qrNYOF4cpXMz"},"source":["\n","fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n","\n","fig.add_trace(go.Histogram(x=Time_bars.variation, name=\"<b>Time Bars\"))\n","\n","fig.add_trace(go.Histogram(x=Tick_bars.variation, name=\"<b>Tick Bars\"))\n","\n","fig.add_trace(go.Histogram(x=Volume_bars.variation, name=\"<b>Volume Bars\"))\n","\n","fig.add_trace(go.Histogram(x=Dollar_bars.variation, name=\"<b>Dollar Bars\"))\n","\n","# Overlay both histograms\n","fig.update_layout(barmode='stack')\n","# Reduce opacity to see both histograms\n","fig.update_traces(opacity=0.4)\n","\n","fig.update_layout(\n","    legend=dict(\n","        x=0.85,\n","        y=0.9,\n","        traceorder=\"normal\",\n","        font=dict(\n","            family=\"sans-serif\",\n","            size=12,\n","            color=\"black\"\n","        ),\n","    )\n",")\n","fig.update_layout(\n","    xaxis_title=\"<b>% of price change within candle (max-low)/max</b>\",\n","    yaxis_title=\"Frequency\",\n",")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LRF1A_8FsSSg"},"source":["pio.write_image(fig, 'Candle_price_change.png', width=1720, height=540)"],"execution_count":null,"outputs":[]}]}